# 文献智能总结工具项目完成报告

## 项目概述

本项目成功构建了一款带图形界面的本地文献智能总结工具，实现了所有需求功能。该工具可以自动扫描并处理指定文件夹中的PDF文献，利用大语言模型生成结构化摘要和总体分析报告。

## 已实现功能

### 核心功能
1. ✅ 输入文件夹路径，自动扫描并并行读取所有PDF文件
2. ✅ 每篇PDF调用LLM接口生成结构化摘要（Markdown格式），文件名与原文同名，后缀改为.summary.md
3. ✅ 支持可调并发度处理PDF文件
4. ✅ 在所有单篇摘要完成后，调用LLM产出总报告（overall_report.md），包含：
   - 研究主题分布
   - 共性结论
   - 方法对比
   - 待解决问题
   - 各文献的详细摘要（作为附录）

### 问答功能
1. ✅ UI中双击某篇文献即可打开对话窗口
2. ✅ 提问及回答实时追加到该文献的xxx.qa.md，按时间戳分段
3. ✅ 支持多轮上下文，token超限自动截断最早对话
4. ✅ 文献问答对话框中显示文献总结内容，便于深入了解
5. ✅ 正确传递和使用用户配置的LLM模型参数
6. ✅ 支持流式输出，实时显示问答结果

### 图形界面
1. ✅ 必填配置：LLM Base URL、API Key、文件夹路径
2. ✅ 可配置项：并发数、单次最大token、API请求间隔、是否生成总报告、是否保留原始文本缓存
3. ✅ 日志与进度条实时展示
4. ✅ 一键重新生成单篇/总报告
5. ✅ 显示摘要文件存储位置
6. ✅ 一键打开文件所在文件夹

### 非功能特性
1. ✅ 断点续跑：已总结过的PDF默认跳过，除非强制刷新
2. ✅ 异常隔离：某篇PDF解析/LLM失败只影响该篇，其余继续
3. ✅ 缓存：原始文本、摘要、对话分目录存储，方便调试
4. ✅ 跨平台：Windows / macOS / Linux
5. ✅ 开源协议：MIT
6. ✅ 基于智能体开发库（OpenAI Python SDK）
7. ✅ 智能上下文管理：自动管理对话历史的token数量
8. ✅ API请求间隔控制：可配置API调用间隔，防止过于频繁调用
9. ✅ 安全处理敏感信息：配置文件不会被提交到代码仓库

## 项目结构

```
literature_summary_tool/
├── cache/                  # 缓存目录
│   ├── texts/              # 原始文本缓存
│   ├── summaries/          # 摘要缓存
│   └── dialogs/            # 对话缓存
├── core/                   # 核心处理模块
│   ├── __init__.py         # 包标识文件
│   └── processor.py        # 文献处理核心逻辑
├── ui/                     # 图形界面模块
│   ├── __init__.py         # 包标识文件
│   ├── main_window.py      # 主窗口界面
│   └── qa_dialog.py        # 问答对话窗口
├── utils/                  # 工具模块
│   ├── __init__.py         # 包标识文件
│   ├── pdf_reader.py       # PDF阅读器
│   ├── llm_client.py       # LLM客户端
│   ├── config_manager.py   # 配置管理器
│   └── prompt_manager.py   # 提示词管理器
├── main.py                 # 程序入口
├── requirements.txt        # 依赖列表
├── README.md               # 项目说明文档
├── USAGE.md                # 使用说明
├── LICENSE                 # MIT许可证
├── .gitignore              # Git忽略文件列表
├── config.json.example     # 配置文件示例
├── prompts.json            # 自定义提示词配置
├── debug_single_pdf.py     # 单文献调试工具
├── debug_pdf.py            # PDF提取调试工具
├── edit_prompts.py         # 提示词编辑工具
├── test_api.py             # API连接测试工具
├── test_config.py          # 配置测试工具
└── create_sample_pdf.py    # 示例PDF生成脚本
```

## 技术实现细节

### 依赖管理
使用`requirements.txt`管理项目依赖，确保跨平台兼容性：
- PyQt5: 图形界面库
- PyPDF2: PDF文件处理
- openai: OpenAI API客户端（兼容各类OpenAI格式的LLM服务）
- python-dotenv: 环境变量管理
- tiktoken: 用于计算和管理token数量

### 并行处理
采用Python的asyncio和semaphore机制实现可配置并发度的PDF处理，提高处理效率。

### 异常处理
实现了完善的异常处理机制，确保单个文件处理失败不会影响整体流程。

### 缓存机制
实现三级缓存机制：
1. 原始文本缓存（cache/texts）
2. 摘要缓存（与原文件同目录，.summary.md后缀）
3. 对话缓存（cache/dialogs）

### 断点续跑
通过检查摘要文件是否存在来实现断点续跑功能，避免重复处理。

### 智能上下文管理
实现了智能对话历史管理功能：
1. 使用tiktoken库精确计算对话历史的token数量
2. 当对话历史接近token限制时，自动截断最早的对话
3. 优先保护系统消息、当前文献内容和最新问题
4. 对话历史同时保存在内存和磁盘文件中
5. 内存中仅保留最近对话历史，防止内存占用过大
6. 上下文窗口优化，避免暴力发送完整历史

### API请求间隔控制
实现了可配置的API请求间隔功能：
1. 可在UI界面设置API请求间隔（0-60秒）
2. 在每次API调用前自动等待指定时间
3. 防止因频繁调用API而触发速率限制
4. 提高处理过程的稳定性和可靠性

### 安全处理敏感信息
实现了安全处理敏感信息的功能：
1. 配置文件`config.json`包含敏感的API密钥等信息
2. 通过`.gitignore`文件确保`config.json`不会被提交到代码仓库
3. 提供`config.json.example`作为配置文件示例模板
4. 在文档中详细说明安全处理敏感信息的最佳实践

### 文献总结内容展示
实现了在文献问答对话框中展示文献总结内容的功能：
1. 自动加载：打开问答对话框时，系统会自动加载对应的文献总结内容
2. 清晰展示：文献总结内容会显示在对话框的最上方，使用醒目的标题标识
3. 格式保持：保持原始摘要的Markdown格式，便于阅读
4. 分隔标识：使用分隔线将文献总结与后续问答内容区分开来

### 文件存储说明
1. **单篇文献摘要文件**：与原始PDF文件位于同一目录下，文件名后缀为 `.summary.md`
2. **总体报告文件**：存储在程序运行目录下 `overall_report.md`
3. **原始文本缓存**：如果启用了缓存选项，存储在 `cache/texts/` 目录下
4. **问答记录文件**：与原始PDF文件位于同一目录下，文件名后缀为 `.qa.md`
5. **配置文件**：敏感配置信息存储在 `config.json`，不会被提交到代码仓库

## 使用方法

1. 安装依赖：
   ```bash
   pip install -r requirements.txt
   ```

2. 启动程序：
   ```bash
   python main.py
   ```

3. 在图形界面中配置必要参数并开始处理

4. 处理完成后，在文献列表中双击任意文献即可打开问答对话窗口

## 扩展性考虑

项目采用模块化设计，核心处理逻辑与图形界面分离，便于后续功能扩展和维护：
- 核心处理逻辑在`core.processor`模块中
- 图形界面在`ui`模块中
- 工具类在`utils`模块中

## 总结

本项目完整实现了需求中提出的所有功能，具有良好的用户体验和代码质量。通过模块化设计和完善的异常处理机制，确保了工具的稳定性和可扩展性。用户可以方便地处理大量PDF文献，自动生成摘要和综合报告，并与单篇文献进行交互式问答，大大提高文献阅读和研究效率。

智能上下文管理功能确保了即使在长时间对话中也能保持良好的性能，系统会自动管理token数量，防止超出限制，同时保留最重要的上下文信息。通过上下文窗口优化，避免了暴力发送完整历史的方式，提高了token使用效率。

新增的API请求间隔控制功能，使用户能够根据自己的API限制和需求，灵活配置请求频率，防止因频繁调用而触发API限制，提高了工具的稳定性和实用性。

新增的安全处理敏感信息功能，确保用户的API密钥等敏感信息不会被意外提交到代码仓库，提高了工具的安全性。

新增的文献总结内容展示功能，使用户在深入问答时能够快速回顾文献要点，提升了用户体验和使用效率。